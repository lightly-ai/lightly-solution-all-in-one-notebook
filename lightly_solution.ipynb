{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook needs to run on a x86_64 CPU. We recommend running it on a Linux machine. It works both with and without a Nvidia GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get the Lightly API token and save it here.\n",
    "For the full docs see https://docs.lightly.ai/docs/install-lightly#api-token\n",
    "\"\"\"\n",
    "\n",
    "lightly_token = \"CHANGE_ME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'dataset_clothing'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 3839, done.\u001b[K\n",
      "Resolving deltas: 100% (10/10), done.\n",
      "\u001b[01;34mdataset_clothing/validation\u001b[00m\n",
      "├── \u001b[01;34mdress\u001b[00m [32 entries exceeds filelimit, not opening dir]\n",
      "├── \u001b[01;34mhat\u001b[00m [14 entries exceeds filelimit, not opening dir]\n",
      "├── \u001b[01;34mlongsleeve\u001b[00m [49 entries exceeds filelimit, not opening dir]\n",
      "├── \u001b[01;34moutwear\u001b[00m [24 entries exceeds filelimit, not opening dir]\n",
      "├── \u001b[01;34mpants\u001b[00m [49 entries exceeds filelimit, not opening dir]\n",
      "├── \u001b[01;34mshirt\u001b[00m [29 entries exceeds filelimit, not opening dir]\n",
      "├── \u001b[01;34mshoes\u001b[00m [26 entries exceeds filelimit, not opening dir]\n",
      "├── \u001b[01;34mshorts\u001b[00m [25 entries exceeds filelimit, not opening dir]\n",
      "├── \u001b[01;34mskirt\u001b[00m [12 entries exceeds filelimit, not opening dir]\n",
      "└── \u001b[01;34mt-shirt\u001b[00m [81 entries exceeds filelimit, not opening dir]\n",
      "\n",
      "10 directories, 0 files\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Set the path to the dataset.\n",
    "Here we use the clothing-small dataset and download it. It has about 4k images.\n",
    "If you want to use your own dataset, just set the path to it.\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_path = Path(\"./dataset_clothing\")\n",
    "!git clone https://github.com/alexeygrigorev/clothing-dataset-small.git {str(dataset_path)}\n",
    "\n",
    "# Optional: Set the dataset path to a directory with less images, so that this example finishes faster.\n",
    "dataset_path = dataset_path / \"validation\"\n",
    "\n",
    "!tree --filelimit=10 {str(dataset_path)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hello from Docker!\n",
      "This message shows that your installation appears to be working correctly.\n",
      "... \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test that docker is installed and working.\n",
    "Instructions work for Linux. For other OS see https://docs.docker.com/engine/install/\n",
    "If these command fail, follow our docker installation guide at https://docs.lightly.ai/docs/install-lightly#docker\n",
    "\"\"\"\n",
    "import subprocess\n",
    "\n",
    "def is_nvidia_gpu_available():\n",
    "    try:\n",
    "        subprocess.run([\"nvidia-smi\"], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        return True\n",
    "    except subprocess.CalledProcessError:\n",
    "        return False\n",
    "\n",
    "if is_nvidia_gpu_available():\n",
    "    !sudo docker run --rm --gpus all nvidia/cuda:11.0.3-base-ubuntu20.04 nvidia-smi\n",
    "else:\n",
    "    !sudo docker run --rm hello-world\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest: Pulling from lightly/worker\n",
      "Status: Image is up to date for lightly/worker:latest\n",
      "docker.io/lightly/worker:latest\n",
      "[2024-03-25 13:23:47] Lightly Worker Solution v2.11.1\u001b[0m\n",
      "[2024-03-25 13:23:47] Congratulations! It looks like the Lightly container is running!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Install the Lightly worker and do a quick sanity check. \"\"\"\n",
    "!docker pull lightly/worker:latest\n",
    "!docker run --shm-size=\"1024m\" --rm -it lightly/worker:latest sanity_check=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "\"\"\" Install the Lightly Python SDK. \"\"\"\n",
    "!pip3 install lightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker_id='65806b455ca68c93b29ad6b3'\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Register the Lightly Worker. \"\"\"\n",
    "\n",
    "from lightly.api import ApiWorkflowClient\n",
    "\n",
    "client = ApiWorkflowClient(token=lightly_token)\n",
    "\n",
    "# Create a Lightly Worker. If a worker with this name already exists, the id of the existing\n",
    "# worker is returned.\n",
    "worker_id = client.register_compute_worker(name=\"clothing-worker\")\n",
    "print(f\"{worker_id=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Create a dataset in the Lightly platform and configure the datasource. \"\"\"\n",
    "from lightly.api import ApiWorkflowClient\n",
    "from lightly.openapi_generated.swagger_client import DatasetType\n",
    "from lightly.openapi_generated.swagger_client import DatasourcePurpose\n",
    "\n",
    "# Create the Lightly client to connect to the API.\n",
    "client = ApiWorkflowClient(token=lightly_token)\n",
    "\n",
    "# Create the dataset on the Lightly Platform.\n",
    "client.create_dataset(\n",
    "    dataset_name=\"clothing-small\",\n",
    "    dataset_type=DatasetType.IMAGES\n",
    ")\n",
    "\n",
    "# Configure the datasource.\n",
    "client.set_local_config(\n",
    "    relative_path=\"\",\n",
    "    purpose=DatasourcePurpose.INPUT,\n",
    ")\n",
    "client.set_local_config(\n",
    "    relative_path=\"\",\n",
    "    purpose=DatasourcePurpose.LIGHTLY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduled_run_id='66017ae99aaa3857efbebb6a'\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Schedule a run on the dataset to select 50 samples. \"\"\"\n",
    "\n",
    "scheduled_run_id = client.schedule_compute_worker_run(\n",
    "    worker_config={\"shutdown_when_job_finished\": True},\n",
    "    selection_config={\n",
    "        \"n_samples\": 50,\n",
    "        \"strategies\": [\n",
    "            {\"input\": {\"type\": \"EMBEDDINGS\"}, \"strategy\": {\"type\": \"DIVERSITY\"}}\n",
    "        ],\n",
    "    },\n",
    ")\n",
    "print(f\"{scheduled_run_id=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                   COMMAND                  CREATED         STATUS         PORTS     NAMES\n",
      "0e07286b3970   lightly/worker:latest   \"/bin/bash onprem-do…\"   2 minutes ago   Up 2 minutes             agitated_shamir\n",
      "input_mount:\n",
      "/GitHub/lightly-solution-all-in-one-notebook/dataset_clothing/validation\n",
      "lightly_mount:\n",
      "./lightly_runs\n",
      "[2024-03-25 13:24:05] Lightly Worker Solution v2.11.1\u001b[0m\n",
      "[2024-03-25 13:24:05] You are using docker build: Tue Mar 12 07:56:29 UTC 2024.\u001b[0m\n",
      "[2024-03-25 13:24:05] Starting worker with id '65806b455ca68c93b29ad6b3'...\u001b[0m\n",
      "\u001b[93m[2024-03-25 13:24:05] Worker 2.11.1 can only process jobs scheduled with Lightly Python client 1.5 or higher.\u001b[0m\n",
      "[2024-03-25 13:24:05] Worker with labels '[]' started. Waiting for jobs...\u001b[0m\n",
      "[2024-03-25 13:24:06] Found 1 open jobs.\u001b[0m\n",
      "[2024-03-25 13:24:06] Started job with job_id '66017ae99aaa3857efbebb6a'.\u001b[0m\n",
      "...\n",
      "...\n",
      "[2024-03-25 13:25:34] Done!\u001b[0m\n",
      "[2024-03-25 13:25:36] Finished compute worker run successfully.\u001b[0m\n",
      "[2024-03-25 13:25:37] Shutting down...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run the Lightly Worker to process the run. It mounts the dataset defined earlier.\n",
    "\"\"\"\n",
    "lightly_path = \"./lightly_runs\"\n",
    "\n",
    "# See if there is another running Lightly Worker that might pick up the job instead.\n",
    "!docker ps\n",
    "\n",
    "!echo \"input_mount:\"\n",
    "!echo {str(dataset_path.absolute())}\n",
    "!echo \"lightly_mount:\"\n",
    "!echo {lightly_path}\n",
    "\n",
    "gpus = \"--gpus all\" if is_nvidia_gpu_available() else \"\"\n",
    "!docker run --shm-size=\"1024m\" {gpus} --rm -it \\\n",
    "    -v {str(dataset_path.absolute())}:/input_mount:ro \\\n",
    "    -v {lightly_path}:/lightly_mount \\\n",
    "    -e LIGHTLY_TOKEN={lightly_token} \\\n",
    "    -e LIGHTLY_WORKER_ID={worker_id}\\\n",
    "    lightly/worker:latest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You succesfully ran the Lightly solution.\n",
    "Now you can view and explore the dataset interactively on the [Lightly Platform](https://app.lightly.ai).\n",
    "To not only see the metadata and distribution, but also the images itself, you need to serve them from your local disk to your local browser by using the `lightly-serve` CLI command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting server, listening at 'localhost:3456'\n",
      "Serving files in 'dataset_clothing/validation' and './lightly_runs'\n"
     ]
    }
   ],
   "source": [
    "!lightly-serve input_mount={str(dataset_path)} lightly_mount={lightly_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case your browser runs on a different machine than your notebook, you also need to forward a port, see our [docs](https://docs.lightly.ai/docs/local-storage#view-local-data-in-remote-machine-in-lightly-platform)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
